{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7Y2DPf4YSfpk"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","# -*- author : Vincent Roduit -*-\n","# -*- date : 2023-11-25 -*-\n","# -*- Last revision: 2023-11-25 -*-\n","# -*- python version : 3.11.6 -*-\n","# -*- Description: Notebook that summarize results-*-"]},{"cell_type":"markdown","metadata":{},"source":["# <center> CS -433 Machine Learning </center>\n","## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n","### <center>Road Segmentation </center>\n","--- "]},{"cell_type":"markdown","metadata":{},"source":["### Preparing environment for Google Colaboratory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23466,"status":"ok","timestamp":1701525786548,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-60},"id":"T_aLiNuUSj2c","outputId":"099b6525-775a-4e16-884f-d1b58752d0f6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1122,"status":"ok","timestamp":1701525787660,"user":{"displayName":"Vincent Roduit","userId":"13076277421100865046"},"user_tz":-60},"id":"XP-aN9mZSrUT","outputId":"1575db20-218c-4410-825b-2eaabffbd762"},"outputs":[],"source":["%cd /content/drive/MyDrive/ml-project-2-team-slo/source"]},{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzABR_GxSfpp"},"outputs":[],"source":["#import libraries\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","#import model parameters\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim import Adam\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1rcJzrbSfpq"},"outputs":[],"source":["#import files\n","from data_processing import*\n","from visualization import visualize, visualize_patch\n","import constants\n","from test_data import TestData\n","\n","#import models\n","from cnn import Basic_CNN\n","from logistic_regression import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set random seed for reproducibility\n","torch.manual_seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Data wrangling and visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["myDatas = AdvancedProcessing(standardize=False)\n","myDatas.proceed()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["visualize(myDatas.imgs, myDatas.gt_imgs, index=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["visualize_patch(myDatas.X_train[0].transpose(1,2,0))"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Define and train models"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Logistic regression"]},{"cell_type":"markdown","metadata":{},"source":["A first attempt could be to try with some linear model. The first approach here is to use a simple logistic regression. In order to use a logistic regression, one need to extract feature from the image. A choice could be to use the mean and the standard deviation as features. The following section will present these approach."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LogisticData = BasicProcessing()\n","LogisticData.load_data()\n","LogisticData.create_patches()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LogReg = LogisticRegression(LogisticData.imgs_patches, LogisticData.gt_imgs_patches)\n","LogReg.compute_vectors()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(LogReg.X[:, 0], LogReg.X[:, 1], c=LogReg.Y, edgecolors=\"k\", cmap=plt.cm.Paired)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["A problem already arises. The datas are not linearly separable."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LogReg.train()\n","LogReg.predict()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'From this model, the accuracy is {LogReg.accuracy*100:.2f}% and the F1 score is {LogReg.f1*100:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["The unsatisfactory results tend us to move to Convolutional Networks, which are more suitable for image datas. "]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Basic Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cnn = Basic_CNN(constants.WINDOW_SIZE)\n","\n","# Define the loss function, optimizer and scheduler\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Train the model\n","cnn.train_model(\n","    optimizer, \n","    scheduler, \n","    criterion, \n","    myDatas.train_dataloader, \n","    myDatas.validate_dataloader, \n","    num_epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["myTestData = TestData(model=cnn)\n","myTestData.proceed()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
